{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics Fundamentals\n",
    "Statistics is primarily about analyzing data samples, and that starts with understanding the distribution of data in a sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Data Distribution\n",
    "A great deal of statistical analysis is based on the way that data values are distributed within the dataset. In this section, we'll explore some statistics that you can use to tell you about the values in a dataset.\n",
    "\n",
    "### Measures of Central Tendency\n",
    "The term *measures of central tendency* sounds a bit grand, but really it's just a fancy way of saying that we're interested in knowing where the middle value in our data is. For example, suppose decide to conduct a study into the comparative salaries of people who graduated from the same school. You might record the results like this:\n",
    "\n",
    "| Name     | Salary      |\n",
    "|----------|-------------|\n",
    "| Dan      | 50,000      |\n",
    "| Joann    | 54,000      |\n",
    "| Pedro    | 50,000      |\n",
    "| Rosie    | 189,000     |\n",
    "| Ethan    | 55,000      |\n",
    "| Vicky    | 40,000      |\n",
    "| Frederic | 59,000      |\n",
    "\n",
    "Now, some of the former-students may earn a lot, and others may earn less; but what's the salary in the middle of the range of all salaries?\n",
    "\n",
    "#### Mean\n",
    "A common way to define the central value is to use the *mean*, often called the *average*. This is calculated as the sum of the values in the dataset, divided by the number of observations in the dataset. When the dataset consists of the full population, the mean is represented by the Greek symbol ***&mu;*** (*mu*), and the formula is written like this:\n",
    "\n",
    "\\begin{equation}\\mu = \\frac{\\displaystyle\\sum_{i=1}^{N}X_{i}}{N}\\end{equation}\n",
    "\n",
    "More commonly, when working with a sample, the mean is represented by ***x&#772;*** (*x-bar*), and the formula is written like this (note the lower case letters used to indicate values from a sample):\n",
    "\n",
    "\\begin{equation}\\bar{x} = \\frac{\\displaystyle\\sum_{i=1}^{n}x_{i}}{n}\\end{equation}\n",
    "\n",
    "In the case of our list of heights, this can be calculated as:\n",
    "\n",
    "\\begin{equation}\\bar{x} = \\frac{50000+54000+50000+189000+55000+40000+59000}{7}\\end{equation}\n",
    "\n",
    "Which is **71,000**.\n",
    "\n",
    ">In technical terminology, ***x&#772;*** is a *statistic* (an estimate based on a sample of data) and ***&mu;*** is a *parameter* (a true value based on the entire population). A lot of the time, the parameters for the full population will be impossible (or at the very least, impractical) to measure; so we use statistics obtained from a representative sample to approximate them. In this case, we can use the sample mean of salary for our selection of surveyed students to try to estimate the actual average salary of all students who graduate from our school.\n",
    "\n",
    "The R **mean** function can be applied to a numeric column of a data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = data.frame(name = c('Dan', 'Joann', 'Pedro', 'Rosie', 'Ethan', 'Vicky', 'Frederic'), \n",
    "                Salary = c(50000,54000,50000,189000,55000,40000,59000))\n",
    "mean(df1$Salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, is **71,000** really the central value? Or put another way, would it be reasonable for a graduate of this school to expect to earn $71,000? After all, that's the average salary of a graduate from this school.\n",
    "\n",
    "If you look closely at the salaries, you can see that out of the seven former students, six earn less than the mean salary. The data is *skewed* by the fact that Rosie has clearly managed to find a much higher-paid job than her classmates.\n",
    "\n",
    "#### Median\n",
    "OK, let's see if we can find another definition for the central value that more closely reflects the expected earning potential of students attending our school. Another measure of central tendency we can use is the *median*. To calculate the median, we need to sort the values into ascending order and then find the middle-most value. When there are an odd number of observations, you can find the position of the median value using this formula (where *n* is the number of observations):\n",
    "\n",
    "\\begin{equation}\\frac{n+1}{2}\\end{equation}\n",
    "\n",
    "Remember that this formula returns the *position* of the median value in the sorted list; not the value itself.\n",
    "\n",
    "If the number of observations is even, then things are a little (but not much) more complicated. In this case you calculate the median as the average of the two middle-most values, which are found like this:\n",
    "\n",
    "\\begin{equation}\\frac{n}{2} \\;\\;\\;\\;and \\;\\;\\;\\; \\frac{n}{2} + 1\\end{equation}\n",
    "\n",
    "So, for our graduate salaries; first lets sort the dataset:\n",
    "\n",
    "| Salary      |\n",
    "|-------------|\n",
    "| 40,000      |\n",
    "| 50,000      |\n",
    "| 50,000      |\n",
    "| 54,000      |\n",
    "| 55,000      |\n",
    "| 59,000      |\n",
    "| 189,000     |\n",
    "\n",
    "There's an odd number of observation (7), so the median value is at position (7 + 1) &div; 2; in other words, position 4:\n",
    "\n",
    "| Salary      |\n",
    "|-------------|\n",
    "| 40,000      |\n",
    "| 50,000      |\n",
    "| 50,000      |\n",
    "|***>54,000*** |\n",
    "| 55,000      |\n",
    "| 59,000      |\n",
    "| 189,000     |\n",
    "\n",
    "So the median salary is **54,000**.\n",
    "\n",
    "The R *median** function can be used to compute this statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median(df1$Salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode\n",
    "Another related statistic is the *mode*, which indicates the most frequently occurring value. If you think about it, this is potentially a good indicator of how much a student might expect to earn when they graduate from the school; out of all the salaries that are being earned by former students, the mode is earned by more than any other.\n",
    "\n",
    "Looking at our list of salaries, there are two instances of former students earning **50,000**, but only one instance each for all other salaries:\n",
    "\n",
    "| Salary      |\n",
    "|-------------|\n",
    "| 40,000      |\n",
    "|***>50,000***|\n",
    "|***>50,000***|\n",
    "| 54,000      |\n",
    "| 55,000      |\n",
    "| 59,000      |\n",
    "| 189,000     |\n",
    "\n",
    "The mode is therefore **50,000**.\n",
    "\n",
    "R does not have a mode function, but it is not too hard to write one. The trick is to find the unique values and then the maximum of the tabulated counts of the unique values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mode <- function(x) {\n",
    "   uniq_x <- unique(x)\n",
    "   uniq_x[which.max(tabulate(match(x, uniq_x)))]\n",
    "}\n",
    "\n",
    "get_mode(df1$Salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multimodal Data\n",
    "It's not uncommon for a set of data to have more than one value as the mode. For example, suppose Ethan receives a raise that takes his salary to **59,000**:\n",
    "\n",
    "| Salary      |\n",
    "|-------------|\n",
    "| 40,000      |\n",
    "|***>50,000***|\n",
    "|***>50,000***|\n",
    "| 54,000      |\n",
    "|***>59,000***|\n",
    "|***>59,000***|\n",
    "| 189,000     |\n",
    "\n",
    "Now there are two values with the highest frequency. This dataset is *bimodal*. More you may want to create a **frequency table** to see the number of occurrences of each unique value. The R **table** function computes and prints a frequency table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = data.frame(name = c('Dan', 'Joann', 'Pedro', 'Rosie', 'Ethan', 'Vicky', 'Frederic'), \n",
    "                Salary = c(50000,54000,50000,189000,59000,40000,59000))\n",
    "\n",
    "table(df2$Salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution and Density\n",
    "Now we know something about finding the center, we can start to explore how the data is distributed around it. What we're interested in here is understanding the general \"shape\" of the data distribution so that we can begin to get a feel for what a 'typical' value might be expected to be.\n",
    "\n",
    "We can start by finding the extremes - the minimum and maximum. In the case of our salary data, the lowest paid graduate from our school is Vicky, with a salary of **40,000**; and the highest-paid graduate is Rosie, with **189,000**.\n",
    "\n",
    "The R ***min*** and ***max*** functions return these values.\n",
    "\n",
    "Run the following code to compare the minimum and maximum salaries to the central measures we calculated previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = data.frame(Name = c('Dan', 'Joann', 'Pedro', 'Rosie', 'Ethan', 'Vicky', 'Frederic'),\n",
    "                 Salary = c(50000,54000,50000,189000,55000,40000,59000))\n",
    "\n",
    "print(paste('Min    = ', as.character(min(df3$Salary))))\n",
    "print(paste('Mode   = ', as.character(get_mode(df3$Salary))))\n",
    "print(paste('Median = ', as.character(median(df3$Salary))))\n",
    "print(paste('Mean   = ', as.character(mean(df3$Salary))))\n",
    "print(paste('max    = ', as.character(max(df3$Salary))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine these values, and get a sense for how the data is distributed - for example, we can see that the *mean* is closer to the max than the *median*, and that both are closer to the *min* than to the *max*.\n",
    "\n",
    "However, it's generally easier to get a sense of the distribution by visualizing the data. Let's start by creating a histogram of the salaries, highlighting the *mean* and *median* salaries (the *min*, *max* are fairly self-evident, and the *mode* is wherever the highest bar is):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(repr)\n",
    "options(repr.plot.width=3.5, repr.plot.height=3) # Set the initial plot area dimensions\n",
    "\n",
    "ggplot(df3) + geom_histogram(aes(Salary), bins = 25, fill = 'blue', alpha = 0.4) +\n",
    "              geom_vline(xintercept = mean(df3$Salary), color = 'red', linetype=\"dashed\") +\n",
    "              geom_vline(xintercept = median(df3$Salary), color = 'green', linetype=\"dashed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <span style=\"color:magenta\">***mean***</span> and <span style=\"color:green\">***median***</span> are shown as dashed lines. Note the following:\n",
    "- *Salary* is a continuous data value - graduates could potentially earn any value along the scale, even down to a fraction of cent.\n",
    "- The number of bins in the histogram determines the size of each salary band for which we're counting frequencies. Fewer bins means merging more individual salaries together to be counted as a group.\n",
    "- The majority of the data is on the left side of the histogram, reflecting the fact that most graduates earn between 40,000 and 55,000\n",
    "- The mean is a higher value than the median and mode.\n",
    "- There are gaps in the histogram for salary bands that nobody earns.\n",
    "\n",
    "The histogram shows the relative frequency of each salary band, based on the number of bins. It also gives us a sense of the *density* of the data for each point on the salary scale. With enough data points, and small enough bins, we could view this density as a line that shows the shape of the data distribution.\n",
    "\n",
    "Run the following cell to show the density of the salary data as a line on top of the histogram. Notice that the y in the histogram must be defined to be **..density..** so that the vertical scale of the histogram and density plot are the same. The **adjust** argument determines the span of the smoothing kernel used for the density estimation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(repr)\n",
    "options(repr.plot.width=3.5, repr.plot.height=3) # Set the initial plot area dimensions\n",
    "\n",
    "ggplot(df3, aes(x = Salary)) + \n",
    "              geom_histogram(aes(y=..density..), bins = 25, fill = 'blue', alpha = 0.4) +\n",
    "              geom_density(adjust = 3, size = 0.5, color = 'orange') +\n",
    "              geom_vline(xintercept = mean(df3$Salary), color = 'red', linetype=\"dashed\") +\n",
    "              geom_vline(xintercept = median(df3$Salary), color = 'green', linetype=\"dashed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the density line takes the form of an asymmetric curve that has a \"peak\" on the left and a long tail on the right. We describe this sort of data distribution as being *skewed*; that is, the data is not distributed symmetrically but \"bunched together\" on one side. In this case, the data is bunched together on the left, creating a long tail on the right; and is described as being *right-skewed* because some infrequently occurring high values are pulling the *mean* to the right.\n",
    "\n",
    "Let's take a look at another set of data. We know how much money our graduates make, but how many hours per week do they need to work to earn their salaries? Here's the data:\n",
    "\n",
    "| Name     | Hours |\n",
    "|----------|-------|\n",
    "| Dan      | 41    |\n",
    "| Joann    | 40    |\n",
    "| Pedro    | 36    |\n",
    "| Rosie    | 30    |\n",
    "| Ethan    | 35    |\n",
    "| Vicky    | 39    |\n",
    "| Frederic | 40    |\n",
    "\n",
    "Run the following code to show the distribution of the hours worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = data.frame(Name = c('Dan', 'Joann', 'Pedro', 'Rosie', 'Ethan', 'Vicky', 'Frederic'),\n",
    "                 Salary = c(41,40,36,30,35,39,40))\n",
    "\n",
    "ggplot(df4, aes(x = Salary)) + \n",
    "              geom_histogram(aes(y=..density..), bins = 25, fill = 'blue', alpha = 0.4) +\n",
    "              geom_density(adjust = 1, size = 0.5, color = 'orange') +\n",
    "              geom_vline(xintercept = mean(df4$Salary), color = 'red', linetype=\"dashed\") +\n",
    "              geom_vline(xintercept = median(df4$Salary), color = 'green', linetype=\"dashed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, the distribution is skewed, but this time it's **left-skewed**. Note that the curve is asymmetric with the <span style=\"color:magenta\">***mean***</span> to the left of the <span style=\"color:green\">***median***</span> and the *mode*; and the average weekly working hours skewed to the lower end.\n",
    "\n",
    "Once again, Rosie seems to be getting the better of the deal. She earns more than her former classmates for working fewer hours. Maybe a look at the test scores the students achieved on their final grade at school might help explain her success:\n",
    "\n",
    "| Name     | Grade |\n",
    "|----------|-------|\n",
    "| Dan      | 50    |\n",
    "| Joann    | 50    |\n",
    "| Pedro    | 46    |\n",
    "| Rosie    | 95    |\n",
    "| Ethan    | 50    |\n",
    "| Vicky    | 5     |\n",
    "| Frederic | 57    |\n",
    "\n",
    "Let's take a look at the distribution of these grades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = data.frame(Name = c('Dan', 'Joann', 'Pedro', 'Rosie', 'Ethan', 'Vicky', 'Frederic'),\n",
    "                 Salary = c(50,50,46,95,50,5,57))\n",
    "\n",
    "ggplot(df5, aes(x = Salary)) + \n",
    "              geom_histogram(aes(y=..density..), bins = 25, fill = 'blue', alpha = 0.4) +\n",
    "              geom_density(adjust = 6, size = 0.5, color = 'orange') +\n",
    "              geom_vline(xintercept = mean(df5$Salary), color = 'red', linetype=\"dashed\") +\n",
    "              geom_vline(xintercept = median(df5$Salary), color = 'green', linetype=\"dashed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, the distribution is symmetric, forming a \"bell-shaped\" curve. The <span style=\"color:magenta\">***mean***</span>, <span style=\"color:green\">***median***</span>, and mode are at the same location, and the data tails off evenly on both sides from a central peak.\n",
    "\n",
    "Statisticians call this a *normal* distribution (or sometimes a *Gaussian* distribution), and it occurs quite commonly in many scenarios due to something called the *Central Limit Theorem*, which reflects the way continuous probability works - more about that later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skewness and Kurtosis\n",
    "You can measure *skewness* (in which direction the data is skewed and to what degree) and kurtosis (how \"peaked\" the data is) to get an idea of the shape of the data distribution. In R e1071 package includes **skewness** and **krutosis** functions to compute these statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "library(e1071)\n",
    "\n",
    "skew_kurt = function(col, df){\n",
    "    print(paste(col, 'Skewness = ', as.character(skewness(df[,col]))))\n",
    "    print(paste(col, 'Kurtosis = ', as.character(kurtosis(df[,col]))))\n",
    "    p = ggplot(df, aes_string(x = col)) + \n",
    "              geom_histogram(aes(y=..density..), bins = 25, fill = 'blue', alpha = 0.4) +\n",
    "              geom_density(adjust = 6, size = 0.5, color = 'orange') +\n",
    "              geom_vline(xintercept = mean(df[,col]), color = 'red', linetype=\"dashed\") +\n",
    "              geom_vline(xintercept = median(df[,col]), color = 'green', linetype=\"dashed\")\n",
    "    print(p)\n",
    "}\n",
    "\n",
    "df6 = data.frame(Name = c('Dan', 'Joann', 'Pedro', 'Rosie', 'Ethan', 'Vicky', 'Frederic'),\n",
    "                 Salary = c(50000,54000,50000,189000,55000,40000,59000),\n",
    "                 Hours = c(41,40,36,30,35,39,40),\n",
    "                 Grade = c(50,50,46,95,50,5,57))\n",
    "\n",
    "skew_kurt('Salary', df6)\n",
    "skew_kurt('Hours', df6)\n",
    "skew_kurt('Grade', df6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the distribution of a real dataset - let's see how the heights of the father's measured in Galton's study of parent and child heights are distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(HistData)\n",
    "df_G = GaltonFamilies\n",
    "\n",
    "ggplot(df_G, aes(x = father)) + \n",
    "              geom_histogram(aes(y=..density..), bins = 25, fill = 'blue', alpha = 0.4) +\n",
    "              geom_density(adjust = 6, size = 0.5, color = 'orange') +\n",
    "              geom_vline(xintercept = mean(df_G$father), color = 'magenta', linetype=\"dashed\") +\n",
    "              geom_vline(xintercept = median(df_G$father), color = 'green', linetype=\"dashed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the father's height measurements are approximately normally distributed - in other words, they form a more or less *normal* distribution that is symmetric around the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measures of Variance\n",
    "We can see from the distribution plots of our data that the values in our dataset can vary quite widely. We can use various measures to quantify this variance.\n",
    "\n",
    "#### Range\n",
    "A simple way to quantify the variance in a dataset is to identify the difference between the lowest and highest values. This is called the *range*, and is calculated by subtracting the minimum value from the maximum value.\n",
    "\n",
    "The following R code operates on the existing data frame of our school graduate data, and calculates the *range* for each of the numeric features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numcols = c('Salary', 'Hours', 'Grade')\n",
    "for(col in numcols){\n",
    "    print(paste(col, 'range:', as.character(max(df6[,col]) - min(df6[,col]))))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quartiles\n",
    "The range is easy to calculate, but it's not a particularly useful statistic. For example, a range of 149,000 between the lowest and highest salary does not tell us which value within that range a graduate is most likely to earn -  it doesn't tell us nothing about how the salaries are distributed around the mean within that range.  \n",
    "\n",
    "We can consider the overall spread of the data by dividing those percentiles into four *quartiles*. The first quartile contains the values from the minimum to the 25th percentile, the second from the 25th percentile to the 50th percentile (which is the median), the third from the 50th percentile to the 75th percentile, and the fourth from the 75th percentile to the maximum.\n",
    "\n",
    "In R, you can use the ***quantile*** function to find the threshold values at the 25th, 50th, and 75th percentiles (*quantile* is a generic term for a ranked position, such as a percentile or quartile).\n",
    "\n",
    "Run the following code to find the quartile thresholds for the weekly hours worked by our former students:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile(df6$Hours, probs = c(0.25, 0.5, 0.75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its usually easier to understand how data is distributed across the quartiles by visualizing it. You can use a histogram, but many data scientists use a kind of visualization called a *box plot* (or a *box and whiskers* plot).\n",
    "\n",
    "Let's create a box plot for the weekly hours. Notice the **x = 1** argument, which is necessary to display a single box plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=4, repr.plot.height=5)\n",
    "ggplot(df6, aes(x = 1, y = Hours)) +\n",
    "      geom_boxplot() +\n",
    "      ggtitle('Weekly Hours Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The box plot consists of:\n",
    "- A rectangular *box* that shows where the data between the 25th and 75th percentile (the second and third quartile) lie. This part of the distribution is often referred to as the *interquartile range* - it contains the middle 50 data values.\n",
    "- *Whiskers* that extend from the box to the bottom of the first quartile and the top of the fourth quartile to show the full range of the data.\n",
    "- A line in the box that shows that location of the median (the 50th percentile, which is also the threshold between the second and third quartile)\n",
    "\n",
    "In this case, you can see that the interquartile range is between 35 and 40, with the median nearer the top of that range. The range of the first quartile is from around 30 to 35, and the fourth quartile is from 40 to 41."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers\n",
    "Let's take a look at another box plot - this time showing the distribution of the salaries earned by our former classmates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df6, aes(x = 1, y = Salary)) +\n",
    "      geom_boxplot() +\n",
    "      ggtitle('Salary Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what's going on here?\n",
    "\n",
    "Well, as we've already noticed, Rosie earns significantly more than her former classmates. So much more in fact, that her salary has been identified as an *outlier*. An outlier is a value that is so far from the center of the distribution compared to other values that it skews the distribution by affecting the mean. There are all sorts of reasons that you might have outliers in your data, including data entry errors, failures in sensors or data-generating equipment, or genuinely anomalous values.\n",
    "\n",
    "So what should we do about it?\n",
    "\n",
    "This really depends on the data, and what you're trying to use it for. In this case, let's assume we're trying to figure out what's a reasonable expectation of salary for a graduate of our school to earn. Ignoring for the moment that we have an extremely small dataset on which to base our judgment, it looks as if Rosie's salary could be either an error (maybe she mis-typed it in the form used to collect data) or a genuine anomaly (maybe she became a professional athlete or some other extremely highly paid job). Either way, it doesn't seem to represent a salary that a typical graduate might earn.\n",
    "\n",
    "Let's see what the distribution of the data looks like without the outlier. This process is known as **trimming** of outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trimmed = df6[df6$Salary < 100000,]\n",
    "\n",
    "ggplot(df_trimmed, aes(x = 1, y = Salary)) +\n",
    "      geom_boxplot() +\n",
    "      ggtitle('Salary Distribution, Trimmed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it looks like there's a more even distribution of salaries. It's still not quite symmetrical, but there's much less overall variance. There's potentially some cause here to disregard Rosie's salary data when we compare the salaries, as it is tending to skew the analysis.\n",
    "\n",
    "So is that OK? Can we really just ignore a data value we don't like?\n",
    "\n",
    "Again, it depends on what you're analyzing. Let's take a look at the distribution of final grades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df6, aes(x = 1, y = Grade)) +\n",
    "      geom_boxplot() +\n",
    "      ggtitle('Grade Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again there are outliers, this time at both ends of the distribution. However, think about what this data represents. If we assume that the grade for the final test is based on a score out of 100, it seems reasonable to expect that some students will score very low (maybe even 0) and some will score very well (maybe even 100); but most will get a score somewhere in the middle.  The reason that the low and high scores here look like outliers might just be because we have so few data points. Let's see what happens if we include a few more students in our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = data.frame(Name = c('Dan', 'Joann', 'Pedro', 'Rosie', 'Ethan', 'Vicky', \n",
    "                          'Frederic', 'Jimmie', 'Rhonda', 'Giovanni', 'Francesca', \n",
    "                          'Rajab', 'Naiyana', 'Kian', 'Jenny'),\n",
    "                Grade = c(50,50,46,95,50,5,57,42,26,72,78,60,40,17,85))\n",
    "\n",
    "ggplot(df7, aes(x = 1, y = Grade)) +\n",
    "      geom_boxplot() +\n",
    "      ggtitle('Grade Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With more data, there are some more high and low scores; so we no longer consider the isolated cases to be outliers.\n",
    "\n",
    "The key point to take away here is that you need to really understand the data and what you're trying to do with it, and you need to ensure that you have a reasonable sample size, before determining what to do with outlier values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance and Standard Deviation\n",
    "We've seen how to understand the *spread* of our data distribution using the range, percentiles, and quartiles; and we've seen the effect of outliers on the distribution. Now it's time to look at how to measure the amount of variance in the data.\n",
    "\n",
    "##### Variance\n",
    "Variance is measured as the average of the squared difference from the mean. For a full population, it's indicated by a squared Greek letter *sigma* (***&sigma;<sup>2</sup>***) and calculated like this:\n",
    "\n",
    "\\begin{equation}\\sigma^{2} = \\frac{\\displaystyle\\sum_{i=1}^{N} (X_{i} -\\mu)^{2}}{N}\\end{equation}\n",
    "\n",
    "For a sample, it's indicated as ***s<sup>2</sup>*** calculated like this:\n",
    "\n",
    "\\begin{equation}s^{2} = \\frac{\\displaystyle\\sum_{i=1}^{n} (x_{i} -\\bar{x})^{2}}{n-1}\\end{equation}\n",
    "\n",
    "In both cases, we sum the difference between the individual data values and the mean and square the result. Then, for a full population we just divide by the number of data items to get the average. When using a sample, we divide by the total number of items **minus 1** to correct for sample bias.\n",
    "\n",
    "Let's work this out for our student grades (assuming our data is a sample from the larger student population).\n",
    "\n",
    "First, we need to calculate the mean grade:\n",
    "\n",
    "\\begin{equation}\\bar{x} = \\frac{50+50+46+95+50+5+57}{7}\\approx 50.43\\end{equation}\n",
    "\n",
    "Then we can plug that into our formula for the variance:\n",
    "\n",
    "\\begin{equation}s^{2} = \\frac{(50-50.43)^{2}+(50-50.43)^{2}+(46-50.43)^{2}+(95-50.43)^{2}+(50-50.43)^{2}+(5-50.43)^{2}+(57-50.43)^{2}}{7-1}\\end{equation}\n",
    "\n",
    "So:\n",
    "\n",
    "\\begin{equation}s^{2} = \\frac{0.185+0.185+19.625+1986.485+0.185+2063.885+43.165}{6}\\end{equation}\n",
    "\n",
    "Which simplifies to:\n",
    "\n",
    "\\begin{equation}s^{2} = \\frac{4113.715}{6}\\end{equation}\n",
    "\n",
    "Giving the result:\n",
    "\n",
    "\\begin{equation}s^{2} \\approx 685.619\\end{equation}\n",
    "\n",
    "The higher the variance, the more spread your data is around the mean.\n",
    "\n",
    "In R ***var*** function computes the variance of a vector of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var(df6$Grade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Standard Deviation\n",
    "To calculate the variance, we squared the difference of each value from the mean. If we hadn't done this, the numerator of our fraction would always end up being zero (because the mean is at the center of our values). However, this means that the variance is not in the same unit of measurement as our data - in our case, since we're calculating the variance for grade points, it's in grade points squared; which is not very helpful.\n",
    "\n",
    "To get the measure of variance back into the same unit of measurement, we need to find its square root:\n",
    "\n",
    "\\begin{equation}s = \\sqrt{685.619} \\approx 26.184\\end{equation}\n",
    "\n",
    "So what does this value represent?\n",
    "\n",
    "It's the *standard deviation* for our grades data. More formally, it's calculated like this for a full population:\n",
    "\n",
    "\\begin{equation}\\sigma = \\sqrt{\\frac{\\displaystyle\\sum_{i=1}^{N} (X_{i} -\\mu)^{2}}{N}}\\end{equation}\n",
    "\n",
    "Or like this for a sample:\n",
    "\n",
    "\\begin{equation}s = \\sqrt{\\frac{\\displaystyle\\sum_{i=1}^{n} (x_{i} -\\bar{x})^{2}}{n-1}}\\end{equation}\n",
    "\n",
    "Note that in both cases, it's just the square root of the corresponding variance formula!\n",
    "\n",
    "The R ***sd*** function computes the standard deviation of a vector of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(df6$Grade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Deviation in a Normal Distribution\n",
    "\n",
    "In statistics and data science, we spend a lot of time considering *normal* distributions; because they occur so frequently. The standard deviation has an important relationship to play in a normal distribution.\n",
    "\n",
    "Run the following cell to show a histogram of a *standard normal* distribution (which is a distribution with a mean of 0 and a standard deviation of 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=6, repr.plot.height=3)\n",
    "\n",
    "## Data frame with 100,000 standard Normal values\n",
    "df_normal = data.frame(Grade = rnorm(100000, mean = 0, sd = 1)) \n",
    "\n",
    "std = sd(df_normal$Grade)\n",
    "\n",
    "## Plot the Normal data with the std lines \n",
    "ggplot(df_normal, aes(Grade)) + \n",
    "       geom_histogram(alpha = 0.3, color = 'blue', bins = 50) + \n",
    "       geom_vline(xintercept = std, color = 'magenta', linetype=\"dashed\", size = 1) +\n",
    "       geom_vline(xintercept = 2 * std, color = 'green', linetype=\"dashed\", size = 1) + \n",
    "       geom_line(data = data.frame(x=c(std,-std),y=c(3800,3800)), aes(x,y), color = 'magenta',\n",
    "                 arrow = arrow(length=unit(0.30,\"cm\"), ends = \"both\"), size = 0.8) +\n",
    "       annotate(\"text\", x = 0, y = 4200, label = '1 std (68.26%)') +\n",
    "       geom_vline(xintercept = -std, color = 'magenta', linetype=\"dashed\", size = 1) +\n",
    "       geom_vline(xintercept = -2 * std, color = 'green', linetype=\"dashed\", size = 1) + \n",
    "       geom_line(data = data.frame(x=c(2*std,-2*std),y=c(1000,1000)), aes(x,y), color = 'green',\n",
    "                 arrow = arrow(length=unit(0.30,\"cm\"), ends = \"both\"), size = 0.8) +\n",
    "       annotate(\"text\", x = 0, y = 1300, label = '2 std (68.26%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The horizontal colored lines show the percentage of data within 1, 2, and 3 standard deviations of the mean (plus or minus).\n",
    "\n",
    "In any normal distribution:\n",
    "- Approximately 68.26% of values fall within one standard deviation from the mean.\n",
    "- Approximately 95.45% of values fall within two standard deviations from the mean.\n",
    "- Approximately 99.73% of values fall within three standard deviations from the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Z Score\n",
    "So in a normal (or close to normal) distribution, standard deviation provides a way to evaluate how far from a mean a given range of values falls, allowing us to compare where a particular value lies within the distribution. For example, suppose Rosie tells you she was the highest scoring student among her friends - that doesn't really help us assess how well she scored. She may have scored only a fraction of a point above the second-highest scoring student. Even if we know she was in the top quartile; if we don't know how the rest of the grades are distributed it's still not clear how well she performed compared to her friends.\n",
    "\n",
    "However, if she tells you how many standard deviations higher than the mean her score was, this will help you compare her score to that of her classmates.\n",
    "\n",
    "So how do we know how many standard deviations above or below the mean a particular value is? We call this a *Z Score*, and it's calculated like this for a full population:\n",
    "\n",
    "\\begin{equation}Z = \\frac{x - \\mu}{\\sigma}\\end{equation}\n",
    "\n",
    "or like this for a sample:\n",
    "\n",
    "\\begin{equation}Z = \\frac{x - \\bar{x}}{s}\\end{equation}\n",
    "\n",
    "So, let's examine Rosie's grade of 95. Now that we know the *mean* grade is 50.43 and the *standard deviation* is 26.184, we can calculate the Z Score for this grade like this:\n",
    "\n",
    "\\begin{equation}Z = \\frac{95 - 50.43}{26.184} = 1.702\\end{equation}.\n",
    "\n",
    "So Rosie's grade is 1.702 standard deviations above the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing Data Distribution in R\n",
    "We've seen how to obtain individual statistics in R, but you can also use the ***summary*** function to retrieve summary statistics for all numeric columns in a data frame. These summary statistics include many of the statistics we've examined so far (though it's worth noting that the *median* is not included):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(df6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
